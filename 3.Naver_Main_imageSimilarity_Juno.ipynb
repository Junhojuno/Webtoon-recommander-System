{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN network를 활용하여 이미지간 유사도\n",
    ": pixel값을 column으로 하여 유사도를 구한다.\n",
    "1. training을 시킨 model의 _dense를 추출하여 유사도를 구한다.\n",
    "2. CNN을 통과시켜 feature의 차원이 축소된 이미지 특성값으로 유사도를 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Juno\\\\Desktop\\\\juno_project\\\\Webtoon-Recommender_System'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image as pil\n",
    "from scipy.misc import imread, imresize\n",
    "import os\n",
    "from scipy import ndimage\n",
    "from six.moves import urllib\n",
    "\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Juno\\Desktop\\juno_project\\Webtoon-Recommender_System./0_img/main_image_naver/color/\n",
      "now: 0 finished!!:\r",
      "now: 1 finished!!:\r",
      "now: 2 finished!!:\r",
      "now: 3 finished!!:\r",
      "now: 4 finished!!:\r",
      "now: 5 finished!!:\r",
      "now: 6 finished!!:\r",
      "now: 7 finished!!:\r",
      "now: 8 finished!!:\r",
      "now: 9 finished!!:\r",
      "now: 10 finished!!:\r",
      "now: 11 finished!!:\r",
      "now: 12 finished!!:\r",
      "now: 13 finished!!:\r",
      "now: 14 finished!!:\r",
      "now: 15 finished!!:\r",
      "now: 16 finished!!:\r",
      "now: 17 finished!!:\r",
      "now: 18 finished!!:\r",
      "now: 19 finished!!:\r",
      "now: 20 finished!!:\r",
      "now: 21 finished!!:\r",
      "now: 22 finished!!:\r",
      "now: 23 finished!!:\r",
      "now: 24 finished!!:\r",
      "now: 25 finished!!:\r",
      "now: 26 finished!!:\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 745 images loaded.\n"
     ]
    }
   ],
   "source": [
    "# 웹툰 labeling을 위한 dictionary를 만든다.\n",
    "\n",
    "# Load info\n",
    "info = pd.read_csv(\"data_Juno/webtoon_naver_info_by_genres.csv\")\n",
    "\n",
    "# make dict\n",
    "dic = {}\n",
    "for i, id in enumerate(info.unique_id):\n",
    "    dic[id] = i\n",
    "\n",
    "path = cwd + \"./0_img/main_image_naver/color/\"\n",
    "print(path)\n",
    "flist = os.listdir(path)\n",
    "n_class = len(dic)\n",
    "imgcnt = 0\n",
    "for f in flist:\n",
    "    fullpath = os.path.join(path,f)\n",
    "    currimg = np.asarray(pil.open(fullpath).convert(\"RGB\"))\n",
    "    img = currimg / 255.\n",
    "#     print(img.shape)\n",
    "#     print(imresize(img, (64,64)).shape)\n",
    "#     print(img)\n",
    "    img_r = imresize(img, (32,32))\n",
    "    imgvec = np.reshape(img_r, (1,-1))\n",
    "    \n",
    "    # make labels\n",
    "    id_check = int(f.split(\".\")[0])\n",
    "    label = dic[id_check]\n",
    "    curr_label = np.eye(n_class, n_class)[label:label+1, :]\n",
    "    if imgcnt == 0:\n",
    "        totalimg = imgvec\n",
    "        totallabel = curr_label\n",
    "    else:\n",
    "        totalimg = np.concatenate((totalimg, imgvec), axis=0)\n",
    "        totallabel = np.concatenate((totallabel, curr_label), axis=0)\n",
    "    print(\"now: %s finished!!:\" % imgcnt, end='\\r')\n",
    "    imgcnt += 1\n",
    "print (\"Total %d images loaded.\" % (imgcnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is defined!!\n"
     ]
    }
   ],
   "source": [
    "n_input = 3072\n",
    "n_channel = 32 # convolution filter의 갯수\n",
    "n_classes = 745\n",
    "n_imgch = 3\n",
    "x = tf.placeholder(dtype='float', shape=[None, n_input])\n",
    "y = tf.placeholder(dtype='float', shape=[None, n_classes])\n",
    "\n",
    "stddev = 0.1\n",
    "# convolution filters\n",
    "weights = {\n",
    "    'c1' : tf.Variable(initial_value=tf.random_normal(shape=[3,3,n_imgch,n_channel], stddev=stddev)),\n",
    "    'c2' : tf.Variable(initial_value=tf.random_normal(shape=[3,3,n_channel,32], stddev=stddev)),\n",
    "    'c3' : tf.Variable(initial_value=tf.random_normal(shape=[3,3,32,32], stddev=stddev)),\n",
    "    'd1' : tf.Variable(initial_value=tf.random_normal(shape=[4*4*32,n_classes], stddev=stddev)),\n",
    "}\n",
    "biases = {\n",
    "    'c1' : tf.Variable(initial_value=tf.random_normal(shape=[n_channel], stddev=stddev)),\n",
    "    'c2' : tf.Variable(initial_value=tf.random_normal(shape=[32], stddev=stddev)),\n",
    "    'c3' : tf.Variable(initial_value=tf.random_normal(shape=[32], stddev=stddev)),\n",
    "    'd1' : tf.Variable(initial_value=tf.random_normal(shape=[n_classes], stddev=stddev)),\n",
    "}\n",
    "print(\"Model is defined!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(_x, _w, _b):\n",
    "    # Reshape\n",
    "    _x_r = tf.reshape(_x, shape=[-1,32,32,3])\n",
    "    # Convolution\n",
    "    _conv1 = tf.nn.conv2d(_x_r, _w['c1'], strides=[1,1,1,1], padding='SAME') # zero-padding\n",
    "    # add bias\n",
    "    _conv2 = tf.nn.bias_add(_conv1, _b['c1'])\n",
    "    # Passing the ReLU\n",
    "    _conv3 = tf.nn.relu(_conv2)\n",
    "    # max pooling\n",
    "    # non-overlapping\n",
    "    _pool = tf.nn.max_pool(_conv3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    # 2nd Convolutional Layer\n",
    "    _second = tf.nn.conv2d(_pool, _w['c2'], strides=[1,1,1,1], padding='SAME')\n",
    "    _second = tf.nn.bias_add(_second, _b['c2'])\n",
    "    _second = tf.nn.relu(_second)\n",
    "    _second = tf.nn.max_pool(_second, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    # 3rd Convolutional Layer\n",
    "    _third = tf.nn.conv2d(_second, _w['c3'], strides=[1,1,1,1], padding='SAME')\n",
    "    _third = tf.nn.bias_add(_third, _b['c3'])\n",
    "    _third = tf.nn.relu(_third)\n",
    "    _third = tf.nn.max_pool(_third, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    # fully connected layer, 한 줄로 쫙 편다.\n",
    "    _dense = tf.reshape(_third, shape=[-1,  _w['d1'].get_shape().as_list()[0]])\n",
    "    _logit = tf.add(tf.matmul(_dense, _w['d1']),_b['d1'])\n",
    "    \n",
    "    # Return to dict type\n",
    "    _out = {\n",
    "        'x_r':_x_r, 'conv1':_conv1, 'conv2' : _conv2, 'conv3': _conv3,\n",
    "        'pool': _pool, 'dense': _dense, 'logit':_logit\n",
    "    }\n",
    "    return _out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnout = CNN(x, weights, biases)\n",
    "features = cnnout['dense']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. training을 시킨 model의 _dense를 추출하여 유사도를 구한다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING [./3_NeuralNet_image/main_image/net-9.ckpt]\n",
      "INFO:tensorflow:Restoring parameters from ./3_NeuralNet_image/main_image/net-9.ckpt\n"
     ]
    }
   ],
   "source": [
    "savedir = \"./3_NeuralNet_image/main_image/\"\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "best_epoch = 9\n",
    "restorename = savedir + \"net-\" + str(best_epoch) + \".ckpt\"\n",
    "print (\"LOADING [%s]\" % (restorename))\n",
    "saver.restore(sess, restorename)\n",
    "result = sess.run(features, feed_dict={x:totalimg})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity, euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 512), (745, 512))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].reshape((1,-1)).shape, result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([498,  74,  73, 226,  51], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similar = linear_kernel(result[0].reshape((1,-1)), result).flatten()\n",
    "# 위 코드는 아래와 같은 역할을 한다\n",
    "# cosine_similar = (srch_vector*X.T).toarray().flatten()\n",
    "\n",
    "# 유사한 rawdata index\n",
    "sim_rank_idx = cosine_similar.argsort()[::-1]\n",
    "sim_rank_idx[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1, 622, 552, 676, 593], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similar = euclidean_distances(result[1].reshape((1,-1)), result).flatten()\n",
    "sim_rank_idx = cosine_similar.argsort()\n",
    "sim_rank_idx[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**2. CNN을 통과시켜 feature의 차원이 축소된 이미지 특성값으로 유사도를 구한다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_image = np.array(totalimg, dtype='float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(745, 3072)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnout = CNN(x, weights, biases)\n",
    "features = cnnout['dense']\n",
    "result = sess.run(features, feed_dict={x:total_image})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(745, 512)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   0, 325, 552, 651, 250, 167, 516, 160, 432], dtype=int64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_dist = euclidean_distances(result[1].reshape((1,-1)), result).flatten()\n",
    "sim_rank_idx = euclidean_dist.argsort()\n",
    "sim_rank_idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic2 = {}\n",
    "for k, v in dic.items():\n",
    "    dic2[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670143"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic2[250]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**둘 다 크게 좋은 결과를 도출해내지 못하였다.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
