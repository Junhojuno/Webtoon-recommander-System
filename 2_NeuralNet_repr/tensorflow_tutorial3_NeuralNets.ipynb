{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png','retina'}\n",
    "from IPython.display import clear_output # clear_output() 으로 아웃풋 제거 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  텐서플로우 튜토리얼 - 딥러닝 도구들1\n",
    "- 튜토리얼을 제공하는 깃헙https://github.com/golbin/TensorFlow-Tutorials\n",
    "- 모두를 위한 딥러닝 강의 https://www.youtube.com/watch?v=BS6O0zOGX4E&list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm\n",
    "\n",
    "- 현재 나와있는 이미지 분석 기법들 정리한 블로그\n",
    "    - https://ratsgo.github.io/deep%20learning/2017/10/09/CNNs/\n",
    "\n",
    "\n",
    "## 목차\n",
    "- MNIST (손글씨 숫자 인식)\n",
    "- CNN (이미지처리)\n",
    "    - layers 패키지로 재구성 및 코드비교\n",
    "- Autoencoder (비지도학습)\n",
    "- GAN (비지도 학습 + 생성모델)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "- 머신러닝 학습의 Hello World 와 같은 MNIST(손글씨 숫자 인식) 문제를 신경망으로 풀어봅니다.\n",
    "- 과적합 방지 기법 중 하나인 Dropout 을 사용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신경망 모델 구성중...\n",
      "학습 시작!\n",
      "Epoch: 0003 Avg. cost = 0.112\n",
      "Epoch: 0006 Avg. cost = 0.059\n",
      "Epoch: 0009 Avg. cost = 0.041\n",
      "Epoch: 0012 Avg. cost = 0.032\n",
      "Epoch: 0015 Avg. cost = 0.025\n",
      "Epoch: 0018 Avg. cost = 0.020\n",
      "Epoch: 0021 Avg. cost = 0.022\n",
      "Epoch: 0024 Avg. cost = 0.015\n",
      "Epoch: 0027 Avg. cost = 0.016\n",
      "Epoch: 0030 Avg. cost = 0.015\n",
      "\n",
      "최적화 완료!\n",
      "정확도: 0.9829\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAroAAAGbCAYAAAAr5TMXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAgAAIEr/By58mnR5shF5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f4a78ef60>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 205,
       "width": 349
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# 텐서플로우에 기본 내장된 mnist 모듈을 이용하여 데이터를 로드합니다.\n",
    "# 지정한 폴더에 MNIST 데이터가 없는 경우 자동으로 데이터를 다운로드합니다.\n",
    "# one_hot 옵션은 레이블을 동물 분류 예제에서 보았던 one_hot 방식의 데이터로 만들어줍니다.\n",
    "print(\"mnist예제 받는중\" ,end='\\r')\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "clear_output()\n",
    "print(\"신경망 모델 구성중...\")\n",
    "#########=====================\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "\n",
    "# 입력 값의 차원은 [배치크기, 특성값] 으로 되어 있습니다.\n",
    "# 손글씨 이미지는 28x28 픽셀로 이루어져 있고, 이를 784개의 특성값으로 정합니다.\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "# 결과값은 0~9까지 값을 가짐\n",
    "Y = tf.placeholder(tf.float32, [None,10])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32) # dropout에 사용\n",
    "\n",
    "# 신경망의 레이어는 다음처럼 구성합니다.\n",
    "# 784(입력 특성값)\n",
    "#   -> 256 (히든레이어 뉴런 갯수) -> 256 (히든레이어 뉴런 갯수)\n",
    "#   -> 10 (결과값 0~9 분류)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "# 입력값에 가중치를 곱하고 ReLU 함수를 이용하여 레이어를 만듭니다.\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "# 텐서플로우에 내장된 함수를 이용하여 dropout 을 적용합니다.\n",
    "# 함수에 적용할 레이어와 확률만 넣어주면 됩니다. 겁나 매직!!\n",
    "L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "# L1 레이어의 출력값에 가중치를 곱하고 ReLU 함수를 이용하여 레이어를 만듭니다.\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "L2 = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "# 최종 모델의 출력값은 W3 변수를 곱해 10개의 분류를 가지게 됩니다.\n",
    "model = tf.matmul(L2, W3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "\n",
    "print(\"학습 시작!\")\n",
    "\n",
    "#########======================\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "for epoch in range(30):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        # 텐서플로우의 mnist 모델의 next_batch 함수를 이용해\n",
    "        # 지정한 크기만큼 학습할 데이터를 가져옵니다.\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys,\n",
    "                                                            keep_prob:0.8})\n",
    "        total_cost += cost_val\n",
    "        \n",
    "    if (epoch+1) % 3 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1),\n",
    "              'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
    "    else : \n",
    "        print('Epoch:', '%04d' % (epoch + 1),\n",
    "              'Avg. cost =', '{:.3f}'.format(total_cost / total_batch), end='\\r')\n",
    "\n",
    "print('\\n최적화 완료!')\n",
    "\n",
    "#########===========================\n",
    "# 결과 확인\n",
    "######\n",
    "# model 로 예측한 값과 실제 레이블인 Y의 값을 비교합니다.\n",
    "# tf.argmax 함수를 이용해 예측한 값에서 가장 큰 값을 예측한 레이블이라고 평가합니다.\n",
    "# 예) [0.1 0 0 0.7 0 0.2 0 0 0 0] -> 3\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도:', sess.run(accuracy,\n",
    "                        feed_dict={X: mnist.test.images,\n",
    "                                   Y: mnist.test.labels,\n",
    "                                  keep_prob:1}))\n",
    "\n",
    "\n",
    "\n",
    "#########\n",
    "# 결과 확인 (matplot)\n",
    "######\n",
    "labels = sess.run(model,\n",
    "                  feed_dict={X: mnist.test.images,\n",
    "                             Y: mnist.test.labels,\n",
    "                             keep_prob: 1})\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(10):\n",
    "    subplot = fig.add_subplot(2, 5, i + 1)\n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "    subplot.set_title('%d' % np.argmax(labels[i]))\n",
    "    subplot.imshow(mnist.test.images[i].reshape((28, 28)),\n",
    "                   cmap=plt.cm.gray_r)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "- 이미지 처리 분야에서 가장 유명한 신경망 모델인 CNN 을 이용하여 더 높은 인식률을 만들어봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습시작!델 구성중...\n",
      "Epoch: 0003 Avg. cost = 0.080\n",
      "Epoch: 0006 Avg. cost = 0.044\n",
      "Epoch: 0009 Avg. cost = 0.031\n",
      "Epoch: 0012 Avg. cost = 0.023\n",
      "Epoch: 0015 Avg. cost = 0.016\n",
      "\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "print(\"mnist예제 받는중\" ,end='\\r')\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "clear_output()\n",
    "print(\"신경망 모델 구성중...\", end=\"\\r\")\n",
    "\n",
    "#########===============================\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "\n",
    "# 기존 모델에서는 입력 값을 28x28 하나의 차원으로 구성하였으나,\n",
    "# CNN 모델을 사용하기 위해 2차원 평면과 특성치의 형태를 갖는 구조로 만듭니다.\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# 각각의 변수와 레이어는 다음과 같은 형태로 구성됩니다.\n",
    "# W1 [3 3 1 32] -> [3 3]: 커널 크기, 1: 입력값 X 의 특성수, 32: 필터 갯수\n",
    "# L1 Conv shape=(?, 28, 28, 32)\n",
    "#    Pool     ->(?, 14, 14, 32)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "# tf.nn.conv2d 를 이용해 한칸씩 움직이는 컨볼루션 레이어를 쉽게 만들 수 있습니다.\n",
    "# padding='SAME' 은 커널 슬라이딩시 최외곽에서 한칸 밖으로 더 움직이는 옵션\n",
    "L1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "# Pooling 역시 tf.nn.max_pool 을 이용하여 쉽게 구성할 수 있습니다.\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "# L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "# L2 Conv shape=(?, 14, 14, 64)\n",
    "#    Pool     ->(?, 7, 7, 64)\n",
    "# W2 의 [3, 3, 32, 64] 에서 32 는 L1 에서 출력된 W1 의 마지막 차원, 필터의 크기 입니다.\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "# L2 = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "# FC 레이어: 입력값 7x7x64 -> 출력값 256\n",
    "# Full connect를 위해 직전의 Pool 사이즈인 (?, 7, 7, 64) 를 참고하여 차원을 줄여줍니다.\n",
    "#    Reshape  ->(?, 256)\n",
    "W3 = tf.Variable(tf.random_normal([7 * 7 * 64, 256], stddev=0.01))\n",
    "L3 = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "L3 = tf.matmul(L3, W3)\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob)\n",
    "\n",
    "# 최종 출력값 L3 에서의 출력 256개를 입력값으로 받아서 0~9 레이블인 10개의 출력값을 만듭니다.\n",
    "W4 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L3, W4)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "# 최적화 함수를 RMSPropOptimizer 로 바꿔서 결과를 확인해봅시다.\n",
    "# optimizer = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
    "print(\"학습시작!\")\n",
    "\n",
    "#########================================\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "for epoch in range(15):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # 이미지 데이터를 CNN 모델을 위한 자료형태인 [28 28 1] 의 형태로 재구성합니다.\n",
    "        batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
    "\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs,\n",
    "                                          Y: batch_ys,\n",
    "                                          keep_prob: 0.7})\n",
    "        total_cost += cost_val\n",
    "\n",
    "    if (epoch+1) % 3 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1),\n",
    "              'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
    "    else : \n",
    "        print('Epoch:', '%04d' % (epoch + 1),\n",
    "              'Avg. cost =', '{:.3f}'.format(total_cost / total_batch), end='\\r')\n",
    "\n",
    "print('\\n최적화 완료!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflow.layers를 사용하여 더 쉽고 보기좋게 만들어보자\n",
    "- 신경망 구성을 손쉽게 해 주는 유틸리티 모음인 tensorflow.layers 를 사용해봅니다.\n",
    "- 위의 코드를 재구성한 것이니, 소스를 한 번 비교해보세요.\n",
    "- 이처럼 TensorFlow 에는 간단하게 사용할 수 있는 다양한 함수와 유틸리티들이 매우 많이 마련되어 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "# 기본적으로 inputs, outputs size, kernel_size 만 넣어주면\n",
    "# 활성화 함수 적용은 물론, 컨볼루션 신경망을 만들기 위한 나머지 수치들은 알아서 계산해줍니다.\n",
    "# 특히 Weights 를 계산하는데 xavier_initializer 를 쓰고 있는 등,\n",
    "# 크게 신경쓰지 않아도 일반적으로 효율적인 신경망을 만들어줍니다.\n",
    "L1 = tf.layers.conv2d(X, 32, [3, 3], activation=tf.nn.relu)\n",
    "L1 = tf.layers.max_pooling2d(L1, [2, 2], [2, 2])\n",
    "L1 = tf.layers.dropout(L1, 0.7, is_training)\n",
    "\n",
    "L2 = tf.layers.conv2d(L1, 64, [3, 3], activation=tf.nn.relu)\n",
    "L2 = tf.layers.max_pooling2d(L2, [2, 2], [2, 2])\n",
    "L2 = tf.layers.dropout(L2, 0.7, is_training)\n",
    "\n",
    "L3 = tf.contrib.layers.flatten(L2)\n",
    "L3 = tf.layers.dense(L3, 256, activation=tf.nn.relu)\n",
    "L3 = tf.layers.dropout(L3, 0.5, is_training)\n",
    "\n",
    "model = tf.layers.dense(L3, 10, activation=None)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "for epoch in range(15):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs,\n",
    "                                          Y: batch_ys,\n",
    "                                          is_training: True})\n",
    "        total_cost += cost_val\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "          'Avg. cost =', '{:.4f}'.format(total_cost / total_batch))\n",
    "\n",
    "print('최적화 완료!')\n",
    "\n",
    "#########\n",
    "# 결과 확인\n",
    "######\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도:', sess.run(accuracy,\n",
    "                        feed_dict={X: mnist.test.images.reshape(-1, 28, 28, 1),\n",
    "                                   Y: mnist.test.labels,\n",
    "                                   is_training: False}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder - 비지도학습\n",
    "- 대표적인 비지도(Unsupervised) 학습 방법인 Autoencoder 를 구현해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 Avg. cost = 0.2004\n",
      "Epoch: 0002 Avg. cost = 0.0626\n",
      "Epoch: 0003 Avg. cost = 0.0520\n",
      "Epoch: 0004 Avg. cost = 0.0456\n",
      "Epoch: 0005 Avg. cost = 0.0417\n",
      "Epoch: 0006 Avg. cost = 0.0395\n",
      "Epoch: 0007 Avg. cost = 0.0372\n",
      "Epoch: 0008 Avg. cost = 0.0352\n",
      "Epoch: 0009 Avg. cost = 0.0343\n",
      "Epoch: 0010 Avg. cost = 0.0337\n",
      "Epoch: 0011 Avg. cost = 0.0334\n",
      "Epoch: 0012 Avg. cost = 0.0331\n",
      "Epoch: 0013 Avg. cost = 0.0327\n",
      "Epoch: 0014 Avg. cost = 0.0326\n",
      "Epoch: 0015 Avg. cost = 0.0324\n",
      "Epoch: 0016 Avg. cost = 0.0323\n",
      "Epoch: 0017 Avg. cost = 0.0322\n",
      "Epoch: 0018 Avg. cost = 0.0320\n",
      "Epoch: 0019 Avg. cost = 0.0316\n",
      "Epoch: 0020 Avg. cost = 0.0310\n",
      "최적화 완료!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ8AAAEYCAYAAADyAFe2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHwQ6TXHg2kpqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16d8b52ee80>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 140,
       "width": 591
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "#########\n",
    "# 옵션 설정\n",
    "######\n",
    "learning_rate = 0.01\n",
    "training_epoch = 20\n",
    "batch_size = 100\n",
    "# 신경망 레이어 구성 옵션\n",
    "n_hidden = 256  # 히든 레이어의 뉴런 갯수\n",
    "n_input = 28*28   # 입력값 크기 - 이미지 픽셀수\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "# Y 가 없습니다. 입력값을 Y로 사용하기 때문입니다.\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "\n",
    "# 인코더 레이어와 디코더 레이어의 가중치와 편향 변수를 설정합니다.\n",
    "# 다음과 같이 이어지는 레이어를 구성하기 위한 값들 입니다.\n",
    "# input -> encode -> decode -> output\n",
    "W_encode = tf.Variable(tf.random_normal([n_input, n_hidden]))\n",
    "b_encode = tf.Variable(tf.random_normal([n_hidden]))\n",
    "# sigmoid 함수를 이용해 신경망 레이어를 구성합니다.\n",
    "# sigmoid(X * W + b)\n",
    "# 인코더 레이어 구성\n",
    "encoder = tf.nn.sigmoid(\n",
    "                tf.add(tf.matmul(X, W_encode), b_encode))\n",
    "\n",
    "# encode 의 아웃풋 크기를 입력값보다 작은 크기로 만들어 정보를 압축하여 특성을 뽑아내고,\n",
    "# decode 의 출력을 입력값과 동일한 크기를 갖도록하여 입력과 똑같은 아웃풋을 만들어 내도록 합니다.\n",
    "# 히든 레이어의 구성과 특성치을 뽑아내는 알고리즘을 변경하여 다양한 오토인코더를 만들 수 있습니다.\n",
    "W_decode = tf.Variable(tf.random_normal([n_hidden, n_input]))\n",
    "b_decode = tf.Variable(tf.random_normal([n_input]))\n",
    "# 디코더 레이어 구성\n",
    "# 이 디코더가 최종 모델이 됩니다.\n",
    "decoder = tf.nn.sigmoid(\n",
    "                tf.add(tf.matmul(encoder, W_decode), b_decode))\n",
    "\n",
    "# 디코더는 인풋과 최대한 같은 결과를 내야 하므로, 디코딩한 결과를 평가하기 위해\n",
    "# 입력 값인 X 값을 평가를 위한 실측 결과 값으로하여 decoder 와의 차이를 손실값으로 설정합니다.\n",
    "cost = tf.reduce_mean(tf.pow(X - decoder, 2))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "for epoch in range(training_epoch):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs})\n",
    "        total_cost += cost_val\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "          'Avg. cost =', '{:.4f}'.format(total_cost / total_batch))\n",
    "\n",
    "print('최적화 완료!')\n",
    "\n",
    "#########\n",
    "# 결과 확인\n",
    "# 입력값(위쪽)과 모델이 생성한 값(아래쪽)을 시각적으로 비교해봅니다.\n",
    "######\n",
    "sample_size = 10\n",
    "\n",
    "samples = sess.run(decoder,\n",
    "                   feed_dict={X: mnist.test.images[:sample_size]})\n",
    "\n",
    "fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
    "\n",
    "for i in range(sample_size):\n",
    "    ax[0][i].set_axis_off()\n",
    "    ax[1][i].set_axis_off()\n",
    "    ax[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "    ax[1][i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN\n",
    "- 2016년에 가장 관심을 많이 받았던 비감독(Unsupervised) 학습 방법인\n",
    "- Generative Adversarial Network(GAN)을 구현해봅니다.\n",
    "- https://arxiv.org/abs/1406.2661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"트레이닝 셋 로드중...\")\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "clear_output()\n",
    "print(\"트레이닝 셋 로드 완료!\")\n",
    "#########\n",
    "# 옵션 설정\n",
    "######\n",
    "total_epoch = 200\n",
    "batch_size = 100\n",
    "learning_rate = 0.0002\n",
    "# 신경망 레이어 구성 옵션\n",
    "n_hidden = 256\n",
    "n_input = 28 * 28\n",
    "n_noise = 128 #생성기의 입력값으로 사용할 노이즈의 크기\n",
    "print(\"모델구성중...\",end=\"\\r\")\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "# GAN도 Unsupervised 학습이므로 Autoencoder 처럼 Y를 사용하지 않는다.\n",
    "X = tf.placeholder(tf.float32,[None, n_input])\n",
    "# 노이즈 Z를 입력값으로 사용\n",
    "Z = tf.placeholder(tf.float32,[None, n_noise])\n",
    "\n",
    "# 생성기 신경망에 사용하는 변수들\n",
    "G_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden], stddev=0.01))\n",
    "G_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "G_W2 = tf.Variable(tf.random_normal([n_hidden, n_input], stddev=0.01))\n",
    "G_b2 = tf.Variable(tf.zeros([n_input]))\n",
    "\n",
    "# 판별기 신경망에 사용하는 변수들\n",
    "D_W1 = tf.Variable(tf.random_normal([n_input, n_hidden], stddev=0.01))\n",
    "D_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "# 판별기의 최종 결과값은 얼마나 진짜와 가깝냐를 판단하는 한 개의 스칼라값임\n",
    "D_W2 = tf.Variable(tf.random_normal([n_hidden, 1], stddev=0.01))\n",
    "D_b2 = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "\n",
    "###\n",
    "# 신경망 구성\n",
    "\n",
    "print(\"신경망 구성중...\",end=\"\\r\")\n",
    "\n",
    "# 생성기(G) 신경망을 구성합니다.\n",
    "def generator(noise_z):\n",
    "    hidden = tf.nn.relu(tf.matmul(noise_z, G_W1) + G_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden,G_W2) + G_b2)\n",
    "    return output\n",
    "\n",
    "# 판별기(D) 신경망을 구성합니다.\n",
    "def discriminator(inputs):\n",
    "    hidden = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden, D_W2) + D_b2)\n",
    "    return output\n",
    "\n",
    "# 랜덤한 노이즈(Z)를 만듭니다.\n",
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.normal(size=(batch_size, n_noise))\n",
    "\n",
    "# 노이즈를 이용해 랜덤한 이미지를 생성합니다.\n",
    "G = generator(Z)\n",
    "# 노이즈를 이용해 생성한 이미지가 진자 이미지인지 구합니다.\n",
    "D_gene = discriminator(G)\n",
    "# 진짜 이미지를 이용해 판별한 값을 구합니다.\n",
    "D_real = discriminator(X)\n",
    "\n",
    "# 논문에 따르면, GAN 모델의 최적화는 loss_G 와 loss_D 를 최대화 하는 것 입니다.\n",
    "# 다만 loss_D와 loss_G는 서로 연관관계가 있기 때문에 두 개의 손실값이 항상 같이 증가하는 경향을 보이지는 않을 것 입니다.\n",
    "# loss_D가 증가하려면 loss_G는 하락해야하고, loss_G가 증가하려면 loss_D는 하락해야하는 경쟁관계에 있기 때문입니다.\n",
    "# 논문의 수식에 따른 다음 로직을 보면 loss_D 를 최대화하기 위해서는 D_gene 값을 최소화하게 됩니다.\n",
    "# 판별기에 진짜 이미지를 넣었을 때에도 최대값을 : tf.log(D_real)\n",
    "# 가짜 이미지를 넣었을 때에도 최대값을 : tf.log(1 - D_gene)\n",
    "# 갖도록 학습시키기 때문입니다.\n",
    "# 이것은 판별기는 생성기가 만들어낸 이미지가 가짜라고 판단하도록 판별기 신경망을 학습시킵니다.\n",
    "loss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1-D_gene))\n",
    "# 반면 loss_G 를 최대화하기 위해서는 D_gene 값을 최대화하게 되는데,\n",
    "# 이것은 가짜 이미지를 넣었을 때, 판별기가 최대한 실제 이미지라고 판단하도록 생성기 신경망을 학습시킵니다.\n",
    "# 논문에서는 loss_D 와 같은 수식으로 최소화 하는 생성기를 찾지만,\n",
    "# 결국 D_gene 값을 최대화하는 것이므로 다음과 같이 사용할 수 있습니다.\n",
    "loss_G = tf.reduce_mean(tf.log(D_gene))\n",
    "\n",
    "# loss_D 를 구할때는 판별기 신경망에 사용되는 변수만 사용하고,\n",
    "# loss_G 를 구할때는 생성기 신경망에 사용되는 변수만 사용하여 최적화한다\n",
    "D_var_list = [D_W1, D_b1, D_W2, D_b2]\n",
    "G_var_list = [G_W1, G_b1, G_W2, G_b2]\n",
    "\n",
    "# GAN 논문의 수식에 따르면 loss 를 극대화 해야하지만, minimize 하는 최적화 함수를 사용하기 때문에\n",
    "# 최적화 하려는 loss_D 와 loss_G 에 음수 부호를 붙여줍니다.\n",
    "train_D = tf.train.AdamOptimizer(learning_rate).minimize(-loss_D, var_list=D_var_list)\n",
    "train_G = tf.train.AdamOptimizer(learning_rate).minimize(-loss_G, var_list=G_var_list)\n",
    "\n",
    "\n",
    "print(\"신경망 모델 학습중...\")\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "loss_val_D, loss_val_G = 0, 0\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    print('running epoch ',epoch,'...',end=\"\\r\")\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "        \n",
    "        # 판별기와 생성기 신경망을 각각 학습시킨다.\n",
    "        _, loss_val_D = sess.run([train_D, loss_D], feed_dict = {X:batch_xs, Z:noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G], feed_dict = {Z:noise})\n",
    "\n",
    "    print('Epoch:', '%04d' % epoch, 'D loss{:.4}'.format(loss_val_D), 'G loss{:4}'.format(loss_val_G))\n",
    "    \n",
    "    #########\n",
    "    # 학습이 되어가는 모습을 보기 위해 주기적으로 이미지를 생성하여 저장\n",
    "    ######\n",
    "    \n",
    "    if epoch ==0 or (epoch + 1) % 5 == 0:\n",
    "        print(\"generate sample image...\",end=\"\")\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G, feed_dict={Z:noise})\n",
    "        \n",
    "        fig, ax = plt.subplots(1,sample_size, figsize=(sample_size,1))\n",
    "        \n",
    "        for i in range(sample_size):\n",
    "            ax[i].set_axis_off()\n",
    "            ax[i].imshow(np.reshape(samples[i], (28,28)))\n",
    "            \n",
    "        plt.savefig('samples/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        print(\"OK!\")\n",
    "        \n",
    "print('최적화 완료!')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GAN 모델을 이용해 단순히 랜덤한 숫자를 생성하는 아닌,\n",
    "- 원하는 손글씨 숫자를 생성하는 모델을 만들어봅니다.\n",
    "- 이런 방식으로 흑백 사진을 컬러로 만든다든가, 또는 선화를 채색한다든가 하는 응용이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신경망 모델 학습중...\n",
      "Epoch: 0000 D loss: 0.007561 G loss: 7.766\n",
      "generate sample image...OK!\n",
      "Epoch: 0001 D loss: 0.006955 G loss: 8.354\n",
      "Epoch: 0002 D loss: 0.002728 G loss: 9.488\n",
      "Epoch: 0003 D loss: 0.0005423 G loss: 9.444\n",
      "Epoch: 0004 D loss: 0.0005298 G loss: 9.315\n",
      "generate sample image...OK!\n",
      "Epoch: 0005 D loss: 0.0002369 G loss: 10.13\n",
      "Epoch: 0006 D loss: 4.167e-05 G loss: 11.78\n",
      "Epoch: 0007 D loss: 0.0003545 G loss: 11.05\n",
      "Epoch: 0008 D loss: 7.399e-05 G loss: 11.32\n",
      "Epoch: 0009 D loss: 3.225e-06 G loss: 14.38\n",
      "generate sample image...OK!\n",
      "Epoch: 0010 D loss: 0.0001301 G loss: 12.14\n",
      "Epoch: 0011 D loss: 0.000324 G loss: 12.46\n",
      "Epoch: 0012 D loss: 2.352e-05 G loss: 16.16\n",
      "Epoch: 0013 D loss: 3.667e-06 G loss: 16.7\n",
      "Epoch: 0014 D loss: 4.792e-07 G loss: 15.43\n",
      "generate sample image...OK!\n",
      "Epoch: 0015 D loss: 1.072e-07 G loss: 16.51\n",
      "Epoch: 0016 D loss: 3.421e-08 G loss: 17.46\n",
      "Epoch: 0017 D loss: 4.047e-08 G loss: 18.36\n",
      "Epoch: 0018 D loss: 2.142e-08 G loss: 17.97\n",
      "Epoch: 0019 D loss: 9.392e-09 G loss: 18.91\n",
      "generate sample image...OK!\n",
      "Epoch: 0020 D loss: 2.755e-08 G loss: 17.77\n",
      "Epoch: 0021 D loss: 0.000153 G loss: 13.29\n",
      "Epoch: 0022 D loss: 1.486e-06 G loss: 18.77\n",
      "Epoch: 0023 D loss: 2.159e-07 G loss: 17.77\n",
      "Epoch: 0024 D loss: 2.129e-05 G loss: 19.98\n",
      "generate sample image...OK!\n",
      "Epoch: 0025 D loss: 1.5e-06 G loss: 14.86\n",
      "Epoch: 0026 D loss: 2.966e-07 G loss: 15.6\n",
      "Epoch: 0027 D loss: 3.426e-07 G loss: 15.89\n",
      "Epoch: 0028 D loss: 5.946e-08 G loss: 19.19\n",
      "Epoch: 0029 D loss: 3.003e-06 G loss: 14.94\n",
      "generate sample image...OK!\n",
      "Epoch: 0030 D loss: 0.0004809 G loss: 17.05\n",
      "Epoch: 0031 D loss: 2.007e-07 G loss: 16.6\n",
      "Epoch: 0032 D loss: 1.768e-07 G loss: 16.12\n",
      "Epoch: 0033 D loss: 1.18e-08 G loss: 18.79\n",
      "Epoch: 0034 D loss: 6.955e-07 G loss: 16.93\n",
      "generate sample image...OK!\n",
      "Epoch: 0035 D loss: 2.278e-08 G loss: 18.94\n",
      "Epoch: 0036 D loss: 1.937e-07 G loss: 17.05\n",
      "Epoch: 0037 D loss: 2.763e-07 G loss: 16.64\n",
      "Epoch: 0038 D loss: 1.423e-05 G loss: 14.68\n",
      "Epoch: 0039 D loss: 1.868e-07 G loss: 15.95\n",
      "generate sample image...OK!\n",
      "Epoch: 0040 D loss: 3.959e-08 G loss: 17.45\n",
      "Epoch: 0041 D loss: 6.317e-08 G loss: 17.37\n",
      "Epoch: 0042 D loss: 2.969e-08 G loss: 17.68\n",
      "Epoch: 0043 D loss: 1.452e-08 G loss: 18.43\n",
      "Epoch: 0044 D loss: 8.351e-07 G loss: 17.35\n",
      "generate sample image...OK!\n",
      "Epoch: 0045 D loss: 7.267e-07 G loss: 16.36\n",
      "Epoch: 0046 D loss: 5.713e-07 G loss: 15.57\n",
      "Epoch: 0047 D loss: 1.151e-07 G loss: 17.33\n",
      "Epoch: 0048 D loss: 4.764e-08 G loss: 23.62\n",
      "Epoch: 0049 D loss: 1.086e-06 G loss: 15.92\n",
      "generate sample image...OK!\n",
      "Epoch: 0050 D loss: 2.746e-07 G loss: 16.58\n",
      "Epoch: 0051 D loss: 8.006e-07 G loss: 16.07\n",
      "Epoch: 0052 D loss: 3.119e-08 G loss: 18.74\n",
      "Epoch: 0053 D loss: 4.003e-09 G loss: 21.21\n",
      "Epoch: 0054 D loss: 3.568e-08 G loss: 18.99\n",
      "generate sample image...OK!\n",
      "Epoch: 0055 D loss: 5.833e-09 G loss: 20.49\n",
      "Epoch: 0056 D loss: 1.643e-06 G loss: 20.6\n",
      "Epoch: 0057 D loss: 1.62e-09 G loss: 22.08\n",
      "Epoch: 0058 D loss: 2.587e-08 G loss: 20.5\n",
      "Epoch: 0059 D loss: 0.105 G loss: 59.52\n",
      "generate sample image...OK!\n",
      "Epoch: 0060 D loss: 3.196e-06 G loss: 14.52\n",
      "Epoch: 0061 D loss: 2.001e-07 G loss: 16.97\n",
      "Epoch: 0062 D loss: 9.559e-07 G loss: 15.63\n",
      "Epoch: 0063 D loss: 8.6e-07 G loss: 16.23\n",
      "Epoch: 0064 D loss: 1.13e-07 G loss: 17.66\n",
      "generate sample image...OK!\n",
      "Epoch: 0065 D loss: 4.842e-07 G loss: 15.63\n",
      "Epoch: 0066 D loss: 4.197e-07 G loss: 16.43\n",
      "Epoch: 0067 D loss: 5.397e-07 G loss: 16.58\n",
      "Epoch: 0068 D loss: 4.169e-09 G loss: 24.36\n",
      "Epoch: 0069 D loss: 6.782e-09 G loss: 21.29\n",
      "generate sample image...OK!\n",
      "Epoch: 0070 D loss: 5.381e-10 G loss: 23.2\n",
      "Epoch: 0071 D loss: 2.641e-12 G loss: 28.48\n",
      "Epoch: 0072 D loss: 2.881e-10 G loss: 23.38\n",
      "Epoch: 0073 D loss: 5.73e-10 G loss: 23.62\n",
      "Epoch: 0074 D loss: 7.239e-11 G loss: 25.6\n",
      "generate sample image...OK!\n",
      "Epoch: 0075 D loss: 4.899e-09 G loss: 36.45\n",
      "Epoch: 0076 D loss: 7.784e-11 G loss: 24.93\n",
      "Epoch: 0077 D loss: 6.191e-09 G loss: 24.71\n",
      "Epoch: 0078 D loss: 8.674e-11 G loss: 24.91\n",
      "Epoch: 0079 D loss: 1.064e-11 G loss: 27.34\n",
      "generate sample image...OK!\n",
      "Epoch: 0080 D loss: 4.499e-11 G loss: 25.76\n",
      "Epoch: 0081 D loss: 9.866e-11 G loss: 25.45\n",
      "Epoch: 0082 D loss: 7.557e-12 G loss: 85.58\n",
      "Epoch: 0083 D loss: 8.081e-11 G loss: 31.51\n",
      "Epoch: 0084 D loss: 2.504e-06 G loss: 14.93\n",
      "generate sample image...OK!\n",
      "Epoch: 0085 D loss: 4.692e-07 G loss: 19.21\n",
      "Epoch: 0086 D loss: 1.733e-07 G loss: 17.52\n",
      "Epoch: 0087 D loss: 1.346e-05 G loss: 13.25\n",
      "Epoch: 0088 D loss: 7.765e-08 G loss: 36.67\n",
      "Epoch: 0089 D loss: 5.128e-07 G loss: 15.71\n",
      "generate sample image...OK!\n",
      "Epoch: 0090 D loss: 8.141e-07 G loss: 14.93\n",
      "Epoch: 0091 D loss: 1.043e-06 G loss: 15.22\n",
      "Epoch: 0092 D loss: 5.652e-07 G loss: 16.26\n",
      "Epoch: 0093 D loss: 8.099e-07 G loss: 16.49\n",
      "Epoch: 0094 D loss: 2.573e-07 G loss: 17.63\n",
      "generate sample image...OK!\n",
      "Epoch: 0095 D loss: 1.036e-06 G loss: 17.42\n",
      "Epoch: 0096 D loss: 8.699e-07 G loss: 17.89\n",
      "Epoch: 0097 D loss: 7.989e-08 G loss: 18.55\n",
      "Epoch: 0098 D loss: 5.105e-08 G loss: 18.95\n",
      "Epoch: 0099 D loss: 5.136e-08 G loss: 18.64\n",
      "generate sample image...OK!\n",
      "Epoch: 0100 D loss: 2.914e-08 G loss: 19.32\n",
      "Epoch: 0101 D loss: 1.033e-07 G loss: 20.17\n",
      "Epoch: 0102 D loss: 3.059e-08 G loss: 18.51\n",
      "Epoch: 0103 D loss: 3.537e-09 G loss: 23.03\n",
      "Epoch: 0104 D loss: 1.396e-07 G loss: 17.71\n",
      "generate sample image...OK!\n",
      "Epoch: 0105 D loss: 2.573e-09 G loss: 21.21\n",
      "Epoch: 0106 D loss: 3.577e-09 G loss: 21.73\n",
      "Epoch: 0107 D loss: 1.284e-09 G loss: 21.96\n",
      "Epoch: 0108 D loss: 1.146e-09 G loss: 22.22\n",
      "Epoch: 0109 D loss: 9.005e-10 G loss: 22.72\n",
      "generate sample image...OK!\n",
      "Epoch: 0110 D loss: 1.673e-09 G loss: 23.02\n",
      "Epoch: 0111 D loss: 3.591e-10 G loss: 24.26\n",
      "Epoch: 0112 D loss: 9.203e-11 G loss: 25.31\n",
      "Epoch: 0113 D loss: 1.257e-10 G loss: 25.3\n",
      "Epoch: 0114 D loss: 7.59e-11 G loss: 25.69\n",
      "generate sample image...OK!\n",
      "Epoch: 0115 D loss: 1.625e-10 G loss: 25.83\n",
      "Epoch: 0116 D loss: 6.958e-11 G loss: 25.58\n",
      "Epoch: 0117 D loss: 3.515e-11 G loss: 26.13\n",
      "Epoch: 0118 D loss: 7.745e-11 G loss: 25.48\n",
      "Epoch: 0119 D loss: 3.977e-10 G loss: 24.29\n",
      "generate sample image...OK!\n",
      "Epoch: 0120 D loss: 4.246e-10 G loss: 23.74\n",
      "Epoch: 0121 D loss: 1.735e-09 G loss: 21.56\n",
      "Epoch: 0122 D loss: 5.121e-09 G loss: 20.81\n",
      "Epoch: 0123 D loss: 2.688e-08 G loss: 18.89\n",
      "Epoch: 0124 D loss: 1.543e-09 G loss: 21.63\n",
      "generate sample image...OK!\n",
      "Epoch: 0125 D loss: 3.155e-08 G loss: 18.71\n",
      "Epoch: 0126 D loss: 2.14e-08 G loss: 19.55\n",
      "Epoch: 0127 D loss: 3.612e-09 G loss: 21.4\n",
      "Epoch: 0128 D loss: 8.307e-09 G loss: 26.21\n",
      "Epoch: 0129 D loss: 1.249e-18 G loss: 43.52\n",
      "generate sample image...OK!\n",
      "Epoch: 0130 D loss: 2.998e-09 G loss: 21.41\n",
      "Epoch: 0131 D loss: 1.376e-09 G loss: 21.65\n",
      "Epoch: 0132 D loss: 3.851e-10 G loss: 23.09\n",
      "Epoch: 0133 D loss: 3.177e-10 G loss: 22.95\n",
      "Epoch: 0134 D loss: 1.558e-10 G loss: 23.88\n",
      "generate sample image...OK!\n",
      "Epoch: 0135 D loss: 2.338e-10 G loss: 23.88\n",
      "Epoch: 0136 D loss: 2.826e-10 G loss: 23.35\n",
      "Epoch: 0137 D loss: 1.999e-09 G loss: 21.71\n",
      "Epoch: 0138 D loss: 3.055e-10 G loss: 23.53\n",
      "Epoch: 0139 D loss: 2.892e-10 G loss: 23.96\n",
      "generate sample image...OK!\n",
      "Epoch: 0140 D loss: 1.604e-10 G loss: 25.05\n",
      "Epoch: 0141 D loss: 7.377e-11 G loss: 25.99\n",
      "Epoch: 0142 D loss: 1.077e-10 G loss: 24.87\n",
      "Epoch: 0143 D loss: 2.118e-10 G loss: 24.48\n",
      "Epoch: 0144 D loss: 1.497e-08 G loss: 26.05\n",
      "generate sample image...OK!\n",
      "Epoch: 0145 D loss: 4.111e-08 G loss: 22.54\n",
      "Epoch: 0146 D loss: 1.168e-08 G loss: 20.59\n",
      "Epoch: 0147 D loss: 9.125e-09 G loss: 19.72\n",
      "Epoch: 0148 D loss: 1.988e-09 G loss: 22.6\n",
      "Epoch: 0149 D loss: 1.727e-10 G loss: 24.68\n",
      "generate sample image...OK!\n",
      "Epoch: 0150 D loss: 3.038e-10 G loss: 23.93\n",
      "Epoch: 0151 D loss: 7.189e-11 G loss: 25.48\n",
      "Epoch: 0152 D loss: 1.454e-10 G loss: 24.63\n",
      "Epoch: 0153 D loss: 1.228e-10 G loss: 25.27\n",
      "Epoch: 0154 D loss: 3.212e-11 G loss: 26.35\n",
      "generate sample image...OK!\n",
      "Epoch: 0155 D loss: 1.907e-09 G loss: 23.95\n",
      "Epoch: 0156 D loss: 5.787e-12 G loss: 30.92\n",
      "Epoch: 0157 D loss: 1.638e-09 G loss: 24.17\n",
      "Epoch: 0158 D loss: 1.948e-10 G loss: 26.72\n",
      "Epoch: 0159 D loss: 8.961e-11 G loss: 27.4\n",
      "generate sample image...OK!\n",
      "Epoch: 0160 D loss: 7.663e-11 G loss: 28.04\n",
      "Epoch: 0161 D loss: 5.597e-11 G loss: 28.45\n",
      "Epoch: 0162 D loss: 9.488e-11 G loss: 27.47\n",
      "Epoch: 0163 D loss: 2.991e-11 G loss: 28.83\n",
      "Epoch: 0164 D loss: 2.795e-11 G loss: 29.24\n",
      "generate sample image...OK!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0165 D loss: 1.165e-11 G loss: 30.38\n",
      "Epoch: 0166 D loss: 9.049e-12 G loss: 30.46\n",
      "Epoch: 0167 D loss: 5.179e-11 G loss: 28.1\n",
      "Epoch: 0168 D loss: 4.321e-10 G loss: 25.99\n",
      "Epoch: 0169 D loss: 4.863e-11 G loss: 28.05\n",
      "generate sample image...OK!\n",
      "Epoch: 0170 D loss: 4.178e-09 G loss: 22.95\n",
      "Epoch: 0171 D loss: 8.648e-09 G loss: 23.88\n",
      "Epoch: 0172 D loss: 9.265e-10 G loss: 25.87\n",
      "Epoch: 0173 D loss: 1.107e-07 G loss: 19.96\n",
      "Epoch: 0174 D loss: 6.024e-29 G loss: 160.5\n",
      "generate sample image...OK!\n",
      "Epoch: 0175 D loss: 1.801e-19 G loss: 81.14\n",
      "Epoch: 0176 D loss: 4.865e-20 G loss: 61.31\n",
      "Epoch: 0177 D loss: 1.629e-16 G loss: 59.25\n",
      "Epoch: 0178 D loss: 1.232e-20 G loss: 49.2\n",
      "Epoch: 0179 D loss: 1.49e-14 G loss: 49.2\n",
      "generate sample image...OK!\n",
      "Epoch: 0180 D loss: 2.903e-17 G loss: 41.25\n",
      "Epoch: 0181 D loss: 1.512e-12 G loss: 29.7\n",
      "Epoch: 0182 D loss: 3.727e-09 G loss: 23.91\n",
      "Epoch: 0183 D loss: 5.022e-11 G loss: 25.03\n",
      "Epoch: 0184 D loss: 5.945e-10 G loss: 23.27\n",
      "generate sample image...OK!\n",
      "Epoch: 0185 D loss: 1.748e-10 G loss: 24.08\n",
      "Epoch: 0186 D loss: 2.574e-10 G loss: 24.12\n",
      "Epoch: 0187 D loss: 1.542e-10 G loss: 24.34\n",
      "Epoch: 0188 D loss: 5.945e-10 G loss: 23.68\n",
      "Epoch: 0189 D loss: 5.473e-11 G loss: 25.95\n",
      "generate sample image...OK!\n",
      "Epoch: 0190 D loss: 3.401e-11 G loss: 26.74\n",
      "Epoch: 0191 D loss: 1.416e-09 G loss: 21.94\n",
      "Epoch: 0192 D loss: 1.943e-11 G loss: 25.92\n",
      "Epoch: 0193 D loss: 2.235e-11 G loss: 26.31\n",
      "Epoch: 0194 D loss: 9.416e-12 G loss: 26.81\n",
      "generate sample image...OK!\n",
      "Epoch: 0195 D loss: 7.001e-12 G loss: 26.92\n",
      "Epoch: 0196 D loss: 7.375e-11 G loss: 24.65\n",
      "Epoch: 0197 D loss: 7.737e-11 G loss: 24.31\n",
      "Epoch: 0198 D loss: 8.688e-09 G loss: 22.23\n",
      "Epoch: 0199 D loss: 1.905e-09 G loss: 26.61\n",
      "generate sample image...OK!\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "clear_output()\n",
    "print(\"신경망 구성중...\",end=\"\\r\")\n",
    "#########\n",
    "# 옵션 설정\n",
    "######\n",
    "total_epoch = 200\n",
    "batch_size = 100\n",
    "n_hidden = 256\n",
    "n_input = 28 * 28\n",
    "n_noise = 128\n",
    "n_class = 10\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "# 노이즈와 실제 이미지에, 그에 해당하는 숫자에 대한 정보를 넣어주기 위해 사용합니다.\n",
    "Y = tf.placeholder(tf.float32, [None, n_class])\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])\n",
    "\n",
    "def generator(noise, labels):\n",
    "    with tf.variable_scope('generator'):\n",
    "        # noise 값에 labels 정보를 추가합니다.\n",
    "        inputs = tf.concat([noise, labels], 1)\n",
    "\n",
    "        # TensorFlow 에서 제공하는 유틸리티 함수를 이용해 신경망을 매우 간단하게 구성할 수 있습니다.\n",
    "        hidden = tf.layers.dense(inputs, n_hidden,\n",
    "                                 activation=tf.nn.relu)\n",
    "        output = tf.layers.dense(hidden, n_input,\n",
    "                                 activation=tf.nn.sigmoid)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def discriminator(inputs, labels, reuse=None):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        # 노이즈에서 생성한 이미지와 실제 이미지를 판별하는 모델의 변수를 동일하게 하기 위해,\n",
    "        # 이전에 사용되었던 변수를 재사용하도록 합니다.\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "\n",
    "        inputs = tf.concat([inputs, labels], 1)\n",
    "\n",
    "        hidden = tf.layers.dense(inputs, n_hidden,\n",
    "                                 activation=tf.nn.relu)\n",
    "        output = tf.layers.dense(hidden, 1,\n",
    "                                 activation=None)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.uniform(-1., 1., size=[batch_size, n_noise])\n",
    "\n",
    "# 생성 모델과 판별 모델에 Y 즉, labels 정보를 추가하여\n",
    "# labels 정보에 해당하는 이미지를 생성할 수 있도록 유도합니다.\n",
    "G = generator(Z, Y)\n",
    "D_real = discriminator(X, Y)\n",
    "D_gene = discriminator(G, Y, True)\n",
    "\n",
    "# 손실함수는 다음을 참고하여 GAN 논문에 나온 방식과는 약간 다르게 작성하였습니다.\n",
    "# http://bamos.github.io/2016/08/09/deep-completion/\n",
    "# 진짜 이미지를 판별하는 D_real 값은 1에 가깝도록,\n",
    "# 가짜 이미지를 판별하는 D_gene 값은 0에 가깝도록 하는 손실 함수입니다.\n",
    "loss_D_real = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_real, labels=tf.ones_like(D_real)))\n",
    "loss_D_gene = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_gene, labels=tf.zeros_like(D_gene)))\n",
    "# loss_D_real 과 loss_D_gene 을 더한 뒤 이 값을 최소화 하도록 최적화합니다.\n",
    "loss_D = loss_D_real + loss_D_gene\n",
    "# 가짜 이미지를 진짜에 가깝게 만들도록 생성망을 학습시키기 위해, D_gene 을 최대한 1에 가깝도록 만드는 손실함수입니다.\n",
    "loss_G = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_gene, labels=tf.ones_like(D_gene)))\n",
    "\n",
    "# TensorFlow 에서 제공하는 유틸리티 함수를 이용해\n",
    "# discriminator 와 generator scope 에서 사용된 변수들을 쉽게 가져올 수 있습니다.\n",
    "vars_D = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                           scope='discriminator')\n",
    "vars_G = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                           scope='generator')\n",
    "\n",
    "train_D = tf.train.AdamOptimizer().minimize(loss_D,\n",
    "                                            var_list=vars_D)\n",
    "train_G = tf.train.AdamOptimizer().minimize(loss_G,\n",
    "                                            var_list=vars_G)\n",
    "print(\"신경망 모델 학습중...\")\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "loss_val_D, loss_val_G = 0, 0\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    print('running epoch ',epoch,'...',end=\"\\r\")\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "\n",
    "        _, loss_val_D = sess.run([train_D, loss_D],\n",
    "                                 feed_dict={X: batch_xs, Y: batch_ys, Z: noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G],\n",
    "                                 feed_dict={Y: batch_ys, Z: noise})\n",
    "\n",
    "    print('Epoch:', '%04d' % epoch,\n",
    "          'D loss: {:.4}'.format(loss_val_D),\n",
    "          'G loss: {:.4}'.format(loss_val_G))\n",
    "\n",
    "    #########\n",
    "    # 학습이 되어가는 모습을 보기 위해 주기적으로 레이블에 따른 이미지를 생성하여 저장\n",
    "    ######\n",
    "    if epoch == 0 or (epoch + 1) % 5 == 0:\n",
    "        print(\"generate sample image...\",end=\"\")\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G,\n",
    "                           feed_dict={Y: mnist.test.labels[:sample_size],\n",
    "                                      Z: noise})\n",
    "\n",
    "        fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
    "\n",
    "        for i in range(sample_size):\n",
    "            ax[0][i].set_axis_off()\n",
    "            ax[1][i].set_axis_off()\n",
    "\n",
    "            ax[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "            ax[1][i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "\n",
    "        plt.savefig('samples2/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        print(\"OK!\")\n",
    "\n",
    "print('최적화 완료!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n",
    "- 머신러닝 학습의 Hello World 와 같은 MNIST(손글씨 숫자 인식) 문제를 신경망으로 풀어봅니다.\n",
    "- MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 Avg. cost = 0.572\n",
      "Epoch: 0002 Avg. cost = 0.242\n",
      "Epoch: 0003 Avg. cost = 0.179\n",
      "Epoch: 0004 Avg. cost = 0.162\n",
      "Epoch: 0005 Avg. cost = 0.136\n",
      "Epoch: 0006 Avg. cost = 0.138\n",
      "Epoch: 0007 Avg. cost = 0.118\n",
      "Epoch: 0008 Avg. cost = 0.109\n",
      "Epoch: 0009 Avg. cost = 0.101\n",
      "Epoch: 0010 Avg. cost = 0.100\n",
      "Epoch: 0011 Avg. cost = 0.098\n",
      "Epoch: 0012 Avg. cost = 0.100\n",
      "Epoch: 0013 Avg. cost = 0.088\n",
      "Epoch: 0014 Avg. cost = 0.083\n",
      "Epoch: 0015 Avg. cost = 0.082\n",
      "Epoch: 0016 Avg. cost = 0.083\n",
      "Epoch: 0017 Avg. cost = 0.078\n",
      "Epoch: 0018 Avg. cost = 0.083\n",
      "Epoch: 0019 Avg. cost = 0.072\n",
      "Epoch: 0020 Avg. cost = 0.073\n",
      "Epoch: 0021 Avg. cost = 0.079\n",
      "Epoch: 0022 Avg. cost = 0.064\n",
      "Epoch: 0023 Avg. cost = 0.065\n",
      "Epoch: 0024 Avg. cost = 0.073\n",
      "Epoch: 0025 Avg. cost = 0.067\n",
      "Epoch: 0026 Avg. cost = 0.068\n",
      "Epoch: 0027 Avg. cost = 0.070\n",
      "Epoch: 0028 Avg. cost = 0.066\n",
      "Epoch: 0029 Avg. cost = 0.060\n",
      "Epoch: 0030 Avg. cost = 0.061\n",
      "최적화 완료!\n",
      "정확도: 0.9749\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "#########\n",
    "# 옵션 설정\n",
    "######\n",
    "learning_rate = 0.001\n",
    "total_epoch = 30\n",
    "batch_size = 128\n",
    "\n",
    "# RNN 은 순서가 있는 자료를 다루므로,\n",
    "# 한 번에 입력받는 갯수와, 총 몇 단계로 이루어져있는 데이터를 받을지를 설정해야합니다.\n",
    "# 이를 위해 가로 픽셀수를 n_input 으로, 세로 픽셀수를 입력 단계인 n_step 으로 설정하였습니다.\n",
    "n_input = 28\n",
    "n_step = 28\n",
    "n_hidden = 128\n",
    "n_class = 10\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "X = tf.placeholder(tf.float32, [None, n_step, n_input])\n",
    "Y = tf.placeholder(tf.float32, [None, n_class])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([n_hidden, n_class]))\n",
    "b = tf.Variable(tf.random_normal([n_class]))\n",
    "\n",
    "# RNN 에 학습에 사용할 셀을 생성합니다\n",
    "# 다음 함수들을 사용하면 다른 구조의 셀로 간단하게 변경할 수 있습니다\n",
    "# BasicRNNCell,BasicLSTMCell,GRUCell\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "\n",
    "# RNN 신경망을 생성합니다\n",
    "# 원래는 다음과 같은 과정을 거쳐야 하지만\n",
    "# states = tf.zeros(batch_size)\n",
    "# for i in range(n_step):\n",
    "#     outputs, states = cell(X[[:, i]], states)\n",
    "# ...\n",
    "# 다음처럼 tf.nn.dynamic_rnn 함수를 사용하면\n",
    "# CNN 의 tf.nn.conv2d 함수처럼 간단하게 RNN 신경망을 만들어줍니다.\n",
    "# 겁나 매직!!\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "# 결과를 Y의 다음 형식과 바꿔야 하기 때문에\n",
    "# Y : [batch_size, n_class]\n",
    "# outputs 의 형태를 이에 맞춰 변경해야합니다.\n",
    "# outputs : [batch_size, n_step, n_hidden]\n",
    "#        -> [n_step, batch_size, n_hidden]\n",
    "#        -> [batch_size, n_hidden]\n",
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "outputs = outputs[-1]\n",
    "model = tf.matmul(outputs, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # X 데이터를 RNN 입력 데이터에 맞게 [batch_size, n_step, n_input] 형태로 변환합니다.\n",
    "        batch_xs = batch_xs.reshape((batch_size, n_step, n_input))\n",
    "\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        total_cost += cost_val\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "          'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
    "\n",
    "print('최적화 완료!')\n",
    "\n",
    "#########\n",
    "# 결과 확인\n",
    "######\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "test_batch_size = len(mnist.test.images)\n",
    "test_xs = mnist.test.images.reshape(test_batch_size, n_step, n_input)\n",
    "test_ys = mnist.test.labels\n",
    "\n",
    "print('정확도:', sess.run(accuracy,\n",
    "                       feed_dict={X: test_xs, Y: test_ys}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN - Autocomplete\n",
    "- 자연어 처리나 음성 처리 분야에 많이 사용되는 RNN 의 기본적인 사용법을 익힙니다.\n",
    "- 4개의 글자를 가진 단어를 학습시켜, 3글자만 주어지면 나머지 한 글자를 추천하여 단어를 완성하는 프로그램입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 4.489306\n",
      "Epoch: 0002 cost = 3.424325\n",
      "Epoch: 0003 cost = 1.803109\n",
      "Epoch: 0004 cost = 1.747030\n",
      "Epoch: 0005 cost = 1.272434\n",
      "Epoch: 0006 cost = 0.656976\n",
      "Epoch: 0007 cost = 0.600736\n",
      "Epoch: 0008 cost = 0.883471\n",
      "Epoch: 0009 cost = 0.492435\n",
      "Epoch: 0010 cost = 0.486881\n",
      "Epoch: 0011 cost = 0.237423\n",
      "Epoch: 0012 cost = 0.408965\n",
      "Epoch: 0013 cost = 0.318964\n",
      "Epoch: 0014 cost = 0.358206\n",
      "Epoch: 0015 cost = 0.109642\n",
      "Epoch: 0016 cost = 0.167461\n",
      "Epoch: 0017 cost = 0.136134\n",
      "Epoch: 0018 cost = 0.103821\n",
      "Epoch: 0019 cost = 0.135834\n",
      "Epoch: 0020 cost = 0.050831\n",
      "Epoch: 0021 cost = 0.133757\n",
      "Epoch: 0022 cost = 0.073349\n",
      "Epoch: 0023 cost = 0.016282\n",
      "Epoch: 0024 cost = 0.107338\n",
      "Epoch: 0025 cost = 0.033539\n",
      "Epoch: 0026 cost = 0.005302\n",
      "Epoch: 0027 cost = 0.073482\n",
      "Epoch: 0028 cost = 0.025233\n",
      "Epoch: 0029 cost = 0.049873\n",
      "Epoch: 0030 cost = 0.056779\n",
      "최적화 완료!\n",
      "\n",
      "=== 예측 결과 ===\n",
      "입력값: ['wo ', 'wo ', 'de ', 'di ', 'co ', 'co ', 'lo ', 'lo ', 'ki ', 'ki ']\n",
      "예측값: ['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss', 'kind']\n",
      "정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "char_arr = ['a', 'b', 'c', 'd', 'e', 'f', 'g',\n",
    "            'h', 'i', 'j', 'k', 'l', 'm', 'n',\n",
    "            'o', 'p', 'q', 'r', 's', 't', 'u',\n",
    "            'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "# one-hot 인코딩 사용 및 디코딩을 하기 위해 연관 배열을 만듭니다.\n",
    "# {'a': 0, 'b': 1, 'c': 2, ..., 'j': 9, 'k', 10, ...}\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "dic_len = len(num_dic)\n",
    "\n",
    "# 다음 배열은 입력값과 출력값으로 다음처럼 사용할 것 입니다.\n",
    "# wor -> X, d -> Y\n",
    "# woo -> X, d -> Y\n",
    "seq_data = ['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss', 'kind']\n",
    "\n",
    "\n",
    "def make_batch(seq_data):\n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "\n",
    "    for seq in seq_data:\n",
    "        # 여기서 생성하는 input_batch 와 target_batch 는\n",
    "        # 알파벳 배열의 인덱스 번호 입니다.\n",
    "        # [22, 14, 17] [22, 14, 14] [3, 4, 4] [3, 8, 21] ...\n",
    "        input = [num_dic[n] for n in seq[:-1]]\n",
    "        # 3, 3, 15, 4, 3 ...\n",
    "        target = num_dic[seq[-1]]\n",
    "        # one-hot 인코딩을 합니다.\n",
    "        # if input is [0, 1, 2]:\n",
    "        # [[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
    "        #  [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
    "        #  [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]]\n",
    "        input_batch.append(np.eye(dic_len)[input])\n",
    "        # 지금까지 손실함수로 사용하던 softmax_cross_entropy_with_logits 함수는\n",
    "        # label 값을 one-hot 인코딩으로 넘겨줘야 하지만,\n",
    "        # 이 예제에서 사용할 손실 함수인 sparse_softmax_cross_entropy_with_logits 는\n",
    "        # one-hot 인코딩을 사용하지 않으므로 index 를 그냥 넘겨주면 됩니다.\n",
    "        target_batch.append(target)\n",
    "\n",
    "    return input_batch, target_batch\n",
    "\n",
    "#########\n",
    "# 옵션 설정\n",
    "######\n",
    "learning_rate = 0.01\n",
    "n_hidden = 128\n",
    "total_epoch = 30\n",
    "# 타입 스텝: [1 2 3] => 3\n",
    "# RNN 을 구성하는 시퀀스의 갯수입니다.\n",
    "n_step = 3\n",
    "# 입력값 크기. 알파벳에 대한 one-hot 인코딩이므로 26개가 됩니다.\n",
    "# 예) c => [0 0 1 0 0 0 0 0 0 0 0 ... 0]\n",
    "# 출력값도 입력값과 마찬가지로 26개의 알파벳으로 분류합니다.\n",
    "n_input = n_class = dic_len\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "X = tf.placeholder(tf.float32, [None, n_step, n_input])\n",
    "# 비용함수에 sparse_softmax_cross_entropy_with_logits 을 사용하므로\n",
    "# 출력값과의 계산을 위한 원본값의 형태는 one-hot vector가 아니라 인덱스 숫자를 그대로 사용하기 때문에\n",
    "# 다음처럼 하나의 값만 있는 1차원 배열을 입력값으로 받습니다.\n",
    "# [3] [3] [15] [4] ...\n",
    "# 기존처럼 one-hot 인코딩을 사용한다면 입력값의 형태는 [None, n_class] 여야합니다.\n",
    "Y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([n_hidden, n_class]))\n",
    "b = tf.Variable(tf.random_normal([n_class]))\n",
    "\n",
    "# RNN 셀을 생성합니다.\n",
    "cell1 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "# 과적합 방지를 위한 Dropout 기법을 사용합니다.\n",
    "cell1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=0.5)\n",
    "# 여러개의 셀을 조합해서 사용하기 위해 셀을 추가로 생성합니다.\n",
    "cell2 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "\n",
    "# 여러개의 셀을 조합한 RNN 셀을 생성합니다.\n",
    "multi_cell = tf.nn.rnn_cell.MultiRNNCell([cell1, cell2])\n",
    "\n",
    "# tf.nn.dynamic_rnn 함수를 이용해 순환 신경망을 만듭니다.\n",
    "# time_major=True\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_cell, X, dtype=tf.float32)\n",
    "\n",
    "# 최종 결과는 one-hot 인코딩 형식으로 만듭니다\n",
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "outputs = outputs[-1]\n",
    "model = tf.matmul(outputs, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                logits=model, labels=Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "input_batch, target_batch = make_batch(seq_data)\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    _, loss = sess.run([optimizer, cost],\n",
    "                       feed_dict={X: input_batch, Y: target_batch})\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "          'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "print('최적화 완료!')\n",
    "\n",
    "#########\n",
    "# 결과 확인\n",
    "######\n",
    "# 레이블값이 정수이므로 예측값도 정수로 변경해줍니다.\n",
    "prediction = tf.cast(tf.argmax(model, 1), tf.int32)\n",
    "# one-hot 인코딩이 아니므로 입력값을 그대로 비교합니다.\n",
    "prediction_check = tf.equal(prediction, Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction_check, tf.float32))\n",
    "\n",
    "input_batch, target_batch = make_batch(seq_data)\n",
    "\n",
    "predict, accuracy_val = sess.run([prediction, accuracy],\n",
    "                                 feed_dict={X: input_batch, Y: target_batch})\n",
    "\n",
    "predict_words = []\n",
    "for idx, val in enumerate(seq_data):\n",
    "    last_char = char_arr[predict[idx]]\n",
    "    predict_words.append(val[:3] + last_char)\n",
    "\n",
    "print('\\n=== 예측 결과 ===')\n",
    "print('입력값:', [w[:3] + ' ' for w in seq_data])\n",
    "print('예측값:', predict_words)\n",
    "print('정확도:', accuracy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
