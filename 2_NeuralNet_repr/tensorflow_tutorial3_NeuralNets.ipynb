{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png','retina'}\n",
    "from IPython.display import clear_output # clear_output() 으로 아웃풋 제거 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  텐서플로우 튜토리얼 - 딥러닝 도구들1\n",
    "- 튜토리얼을 제공하는 깃헙https://github.com/golbin/TensorFlow-Tutorials\n",
    "\n",
    "## 목차\n",
    "- MNIST (손글씨 숫자 인식)\n",
    "- CNN (이미지처리)\n",
    "    - layers 패키지로 재구성 및 코드비교\n",
    "- Autoencoder (비지도학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "- 머신러닝 학습의 Hello World 와 같은 MNIST(손글씨 숫자 인식) 문제를 신경망으로 풀어봅니다.\n",
    "- 과적합 방지 기법 중 하나인 Dropout 을 사용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신경망 모델 구성중...\n",
      "학습 시작!\n",
      "Epoch: 0003 Avg. cost = 0.112\n",
      "Epoch: 0006 Avg. cost = 0.059\n",
      "Epoch: 0009 Avg. cost = 0.041\n",
      "Epoch: 0012 Avg. cost = 0.032\n",
      "Epoch: 0015 Avg. cost = 0.025\n",
      "Epoch: 0018 Avg. cost = 0.020\n",
      "Epoch: 0021 Avg. cost = 0.022\n",
      "Epoch: 0024 Avg. cost = 0.015\n",
      "Epoch: 0027 Avg. cost = 0.016\n",
      "Epoch: 0030 Avg. cost = 0.015\n",
      "\n",
      "최적화 완료!\n",
      "정확도: 0.9829\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAroAAAGbCAYAAAAr5TMXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAgAAIEr/By58mnR5shF5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f4a78ef60>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 205,
       "width": 349
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# 텐서플로우에 기본 내장된 mnist 모듈을 이용하여 데이터를 로드합니다.\n",
    "# 지정한 폴더에 MNIST 데이터가 없는 경우 자동으로 데이터를 다운로드합니다.\n",
    "# one_hot 옵션은 레이블을 동물 분류 예제에서 보았던 one_hot 방식의 데이터로 만들어줍니다.\n",
    "print(\"mnist예제 받는중\" ,end='\\r')\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "clear_output()\n",
    "print(\"신경망 모델 구성중...\")\n",
    "#########=====================\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "\n",
    "# 입력 값의 차원은 [배치크기, 특성값] 으로 되어 있습니다.\n",
    "# 손글씨 이미지는 28x28 픽셀로 이루어져 있고, 이를 784개의 특성값으로 정합니다.\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "# 결과값은 0~9까지 값을 가짐\n",
    "Y = tf.placeholder(tf.float32, [None,10])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32) # dropout에 사용\n",
    "\n",
    "# 신경망의 레이어는 다음처럼 구성합니다.\n",
    "# 784(입력 특성값)\n",
    "#   -> 256 (히든레이어 뉴런 갯수) -> 256 (히든레이어 뉴런 갯수)\n",
    "#   -> 10 (결과값 0~9 분류)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "# 입력값에 가중치를 곱하고 ReLU 함수를 이용하여 레이어를 만듭니다.\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "# 텐서플로우에 내장된 함수를 이용하여 dropout 을 적용합니다.\n",
    "# 함수에 적용할 레이어와 확률만 넣어주면 됩니다. 겁나 매직!!\n",
    "L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "# L1 레이어의 출력값에 가중치를 곱하고 ReLU 함수를 이용하여 레이어를 만듭니다.\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "L2 = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "# 최종 모델의 출력값은 W3 변수를 곱해 10개의 분류를 가지게 됩니다.\n",
    "model = tf.matmul(L2, W3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "\n",
    "print(\"학습 시작!\")\n",
    "\n",
    "#########======================\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "for epoch in range(30):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        # 텐서플로우의 mnist 모델의 next_batch 함수를 이용해\n",
    "        # 지정한 크기만큼 학습할 데이터를 가져옵니다.\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys,\n",
    "                                                            keep_prob:0.8})\n",
    "        total_cost += cost_val\n",
    "        \n",
    "    if (epoch+1) % 3 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1),\n",
    "              'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
    "    else : \n",
    "        print('Epoch:', '%04d' % (epoch + 1),\n",
    "              'Avg. cost =', '{:.3f}'.format(total_cost / total_batch), end='\\r')\n",
    "\n",
    "print('\\n최적화 완료!')\n",
    "\n",
    "#########===========================\n",
    "# 결과 확인\n",
    "######\n",
    "# model 로 예측한 값과 실제 레이블인 Y의 값을 비교합니다.\n",
    "# tf.argmax 함수를 이용해 예측한 값에서 가장 큰 값을 예측한 레이블이라고 평가합니다.\n",
    "# 예) [0.1 0 0 0.7 0 0.2 0 0 0 0] -> 3\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도:', sess.run(accuracy,\n",
    "                        feed_dict={X: mnist.test.images,\n",
    "                                   Y: mnist.test.labels,\n",
    "                                  keep_prob:1}))\n",
    "\n",
    "\n",
    "\n",
    "#########\n",
    "# 결과 확인 (matplot)\n",
    "######\n",
    "labels = sess.run(model,\n",
    "                  feed_dict={X: mnist.test.images,\n",
    "                             Y: mnist.test.labels,\n",
    "                             keep_prob: 1})\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(10):\n",
    "    subplot = fig.add_subplot(2, 5, i + 1)\n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "    subplot.set_title('%d' % np.argmax(labels[i]))\n",
    "    subplot.imshow(mnist.test.images[i].reshape((28, 28)),\n",
    "                   cmap=plt.cm.gray_r)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "- 이미지 처리 분야에서 가장 유명한 신경망 모델인 CNN 을 이용하여 더 높은 인식률을 만들어봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습시작!델 구성중...\n",
      "Epoch: 0003 Avg. cost = 0.080\n",
      "Epoch: 0006 Avg. cost = 0.044\n",
      "Epoch: 0009 Avg. cost = 0.031\n",
      "Epoch: 0012 Avg. cost = 0.023\n",
      "Epoch: 0015 Avg. cost = 0.016\n",
      "\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "print(\"mnist예제 받는중\" ,end='\\r')\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "clear_output()\n",
    "print(\"신경망 모델 구성중...\", end=\"\\r\")\n",
    "\n",
    "#########===============================\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "\n",
    "# 기존 모델에서는 입력 값을 28x28 하나의 차원으로 구성하였으나,\n",
    "# CNN 모델을 사용하기 위해 2차원 평면과 특성치의 형태를 갖는 구조로 만듭니다.\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# 각각의 변수와 레이어는 다음과 같은 형태로 구성됩니다.\n",
    "# W1 [3 3 1 32] -> [3 3]: 커널 크기, 1: 입력값 X 의 특성수, 32: 필터 갯수\n",
    "# L1 Conv shape=(?, 28, 28, 32)\n",
    "#    Pool     ->(?, 14, 14, 32)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "# tf.nn.conv2d 를 이용해 한칸씩 움직이는 컨볼루션 레이어를 쉽게 만들 수 있습니다.\n",
    "# padding='SAME' 은 커널 슬라이딩시 최외곽에서 한칸 밖으로 더 움직이는 옵션\n",
    "L1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "# Pooling 역시 tf.nn.max_pool 을 이용하여 쉽게 구성할 수 있습니다.\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "# L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "# L2 Conv shape=(?, 14, 14, 64)\n",
    "#    Pool     ->(?, 7, 7, 64)\n",
    "# W2 의 [3, 3, 32, 64] 에서 32 는 L1 에서 출력된 W1 의 마지막 차원, 필터의 크기 입니다.\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "# L2 = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "# FC 레이어: 입력값 7x7x64 -> 출력값 256\n",
    "# Full connect를 위해 직전의 Pool 사이즈인 (?, 7, 7, 64) 를 참고하여 차원을 줄여줍니다.\n",
    "#    Reshape  ->(?, 256)\n",
    "W3 = tf.Variable(tf.random_normal([7 * 7 * 64, 256], stddev=0.01))\n",
    "L3 = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "L3 = tf.matmul(L3, W3)\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob)\n",
    "\n",
    "# 최종 출력값 L3 에서의 출력 256개를 입력값으로 받아서 0~9 레이블인 10개의 출력값을 만듭니다.\n",
    "W4 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L3, W4)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "# 최적화 함수를 RMSPropOptimizer 로 바꿔서 결과를 확인해봅시다.\n",
    "# optimizer = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
    "print(\"학습시작!\")\n",
    "\n",
    "#########================================\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "for epoch in range(15):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # 이미지 데이터를 CNN 모델을 위한 자료형태인 [28 28 1] 의 형태로 재구성합니다.\n",
    "        batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
    "\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs,\n",
    "                                          Y: batch_ys,\n",
    "                                          keep_prob: 0.7})\n",
    "        total_cost += cost_val\n",
    "\n",
    "    if (epoch+1) % 3 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1),\n",
    "              'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
    "    else : \n",
    "        print('Epoch:', '%04d' % (epoch + 1),\n",
    "              'Avg. cost =', '{:.3f}'.format(total_cost / total_batch), end='\\r')\n",
    "\n",
    "print('\\n최적화 완료!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflow.layers를 사용하여 더 쉽고 보기좋게 만들어보자\n",
    "- 신경망 구성을 손쉽게 해 주는 유틸리티 모음인 tensorflow.layers 를 사용해봅니다.\n",
    "- 위의 코드를 재구성한 것이니, 소스를 한 번 비교해보세요.\n",
    "- 이처럼 TensorFlow 에는 간단하게 사용할 수 있는 다양한 함수와 유틸리티들이 매우 많이 마련되어 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "# 기본적으로 inputs, outputs size, kernel_size 만 넣어주면\n",
    "# 활성화 함수 적용은 물론, 컨볼루션 신경망을 만들기 위한 나머지 수치들은 알아서 계산해줍니다.\n",
    "# 특히 Weights 를 계산하는데 xavier_initializer 를 쓰고 있는 등,\n",
    "# 크게 신경쓰지 않아도 일반적으로 효율적인 신경망을 만들어줍니다.\n",
    "L1 = tf.layers.conv2d(X, 32, [3, 3], activation=tf.nn.relu)\n",
    "L1 = tf.layers.max_pooling2d(L1, [2, 2], [2, 2])\n",
    "L1 = tf.layers.dropout(L1, 0.7, is_training)\n",
    "\n",
    "L2 = tf.layers.conv2d(L1, 64, [3, 3], activation=tf.nn.relu)\n",
    "L2 = tf.layers.max_pooling2d(L2, [2, 2], [2, 2])\n",
    "L2 = tf.layers.dropout(L2, 0.7, is_training)\n",
    "\n",
    "L3 = tf.contrib.layers.flatten(L2)\n",
    "L3 = tf.layers.dense(L3, 256, activation=tf.nn.relu)\n",
    "L3 = tf.layers.dropout(L3, 0.5, is_training)\n",
    "\n",
    "model = tf.layers.dense(L3, 10, activation=None)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "for epoch in range(15):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs,\n",
    "                                          Y: batch_ys,\n",
    "                                          is_training: True})\n",
    "        total_cost += cost_val\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "          'Avg. cost =', '{:.4f}'.format(total_cost / total_batch))\n",
    "\n",
    "print('최적화 완료!')\n",
    "\n",
    "#########\n",
    "# 결과 확인\n",
    "######\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도:', sess.run(accuracy,\n",
    "                        feed_dict={X: mnist.test.images.reshape(-1, 28, 28, 1),\n",
    "                                   Y: mnist.test.labels,\n",
    "                                   is_training: False}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder - 비지도학습\n",
    "- 대표적인 비지도(Unsupervised) 학습 방법인 Autoencoder 를 구현해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "#########\n",
    "# 옵션 설정\n",
    "######\n",
    "learning_rate = 0.01\n",
    "training_epoch = 20\n",
    "batch_size = 100\n",
    "# 신경망 레이어 구성 옵션\n",
    "n_hidden = 256  # 히든 레이어의 뉴런 갯수\n",
    "n_input = 28*28   # 입력값 크기 - 이미지 픽셀수\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "# Y 가 없습니다. 입력값을 Y로 사용하기 때문입니다.\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "\n",
    "# 인코더 레이어와 디코더 레이어의 가중치와 편향 변수를 설정합니다.\n",
    "# 다음과 같이 이어지는 레이어를 구성하기 위한 값들 입니다.\n",
    "# input -> encode -> decode -> output\n",
    "W_encode = tf.Variable(tf.random_normal([n_input, n_hidden]))\n",
    "b_encode = tf.Variable(tf.random_normal([n_hidden]))\n",
    "# sigmoid 함수를 이용해 신경망 레이어를 구성합니다.\n",
    "# sigmoid(X * W + b)\n",
    "# 인코더 레이어 구성\n",
    "encoder = tf.nn.sigmoid(\n",
    "                tf.add(tf.matmul(X, W_encode), b_encode))\n",
    "\n",
    "# encode 의 아웃풋 크기를 입력값보다 작은 크기로 만들어 정보를 압축하여 특성을 뽑아내고,\n",
    "# decode 의 출력을 입력값과 동일한 크기를 갖도록하여 입력과 똑같은 아웃풋을 만들어 내도록 합니다.\n",
    "# 히든 레이어의 구성과 특성치을 뽑아내는 알고리즘을 변경하여 다양한 오토인코더를 만들 수 있습니다.\n",
    "W_decode = tf.Variable(tf.random_normal([n_hidden, n_input]))\n",
    "b_decode = tf.Variable(tf.random_normal([n_input]))\n",
    "# 디코더 레이어 구성\n",
    "# 이 디코더가 최종 모델이 됩니다.\n",
    "decoder = tf.nn.sigmoid(\n",
    "                tf.add(tf.matmul(encoder, W_decode), b_decode))\n",
    "\n",
    "# 디코더는 인풋과 최대한 같은 결과를 내야 하므로, 디코딩한 결과를 평가하기 위해\n",
    "# 입력 값인 X 값을 평가를 위한 실측 결과 값으로하여 decoder 와의 차이를 손실값으로 설정합니다.\n",
    "cost = tf.reduce_mean(tf.pow(X - decoder, 2))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "for epoch in range(training_epoch):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs})\n",
    "        total_cost += cost_val\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "          'Avg. cost =', '{:.4f}'.format(total_cost / total_batch))\n",
    "\n",
    "print('최적화 완료!')\n",
    "\n",
    "#########\n",
    "# 결과 확인\n",
    "# 입력값(위쪽)과 모델이 생성한 값(아래쪽)을 시각적으로 비교해봅니다.\n",
    "######\n",
    "sample_size = 10\n",
    "\n",
    "samples = sess.run(decoder,\n",
    "                   feed_dict={X: mnist.test.images[:sample_size]})\n",
    "\n",
    "fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
    "\n",
    "for i in range(sample_size):\n",
    "    ax[0][i].set_axis_off()\n",
    "    ax[1][i].set_axis_off()\n",
    "    ax[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "    ax[1][i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
